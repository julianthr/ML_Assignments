{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e7c32f4",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4a335",
   "metadata": {},
   "source": [
    "##### Relevant Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da65d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:38.971806Z",
     "iopub.status.busy": "2023-03-20T12:56:38.971265Z",
     "iopub.status.idle": "2023-03-20T12:56:40.025084Z",
     "shell.execute_reply": "2023-03-20T12:56:40.023937Z",
     "shell.execute_reply.started": "2023-03-20T12:56:38.971764Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for splitting into training and test set\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# for SVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# for random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# for evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e4e119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.026533Z",
     "iopub.status.busy": "2023-03-20T12:56:40.026177Z",
     "iopub.status.idle": "2023-03-20T12:56:40.344457Z",
     "shell.execute_reply": "2023-03-20T12:56:40.343550Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.026507Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "df = pd.read_csv(\"data.csv\", index_col=0) # user should be index of each row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7c661",
   "metadata": {},
   "source": [
    "##### EDA and Preprocessing of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004a2044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.345605Z",
     "iopub.status.busy": "2023-03-20T12:56:40.345379Z",
     "iopub.status.idle": "2023-03-20T12:56:40.363325Z",
     "shell.execute_reply": "2023-03-20T12:56:40.362657Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.345585Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Addthis</th>\n",
       "      <th>Bebo</th>\n",
       "      <th>Blogcatalog</th>\n",
       "      <th>Blogger</th>\n",
       "      <th>Buddymedia</th>\n",
       "      <th>Cnet</th>\n",
       "      <th>Conduit</th>\n",
       "      <th>Customerlobby</th>\n",
       "      <th>Delicious</th>\n",
       "      <th>Digg</th>\n",
       "      <th>...</th>\n",
       "      <th>Vimeo</th>\n",
       "      <th>Vocus</th>\n",
       "      <th>Wetpaint</th>\n",
       "      <th>Wordpress</th>\n",
       "      <th>Xanga</th>\n",
       "      <th>Yelp</th>\n",
       "      <th>Yfrog</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>Yuku</th>\n",
       "      <th>Click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dmp923122274</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp458034174</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp364043571</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp461339655</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmp549691332</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Addthis  Bebo  Blogcatalog  Blogger  Buddymedia  Cnet  Conduit  \\\n",
       "dmp923122274        0     0            2        0           0     3        6   \n",
       "dmp458034174        0     3            0        0           0     0        1   \n",
       "dmp364043571        0     2            0        0           0     0        0   \n",
       "dmp461339655        0     0            0        0           0     0        0   \n",
       "dmp549691332        0     0            0        0           0     5        7   \n",
       "\n",
       "              Customerlobby  Delicious  Digg  ... Vimeo  Vocus  Wetpaint  \\\n",
       "dmp923122274              0          0     0  ...     0      0         0   \n",
       "dmp458034174              0          0     0  ...     0      0         0   \n",
       "dmp364043571              0          2     0  ...     0      0         0   \n",
       "dmp461339655              0          0     0  ...     0      0         0   \n",
       "dmp549691332              0          0     5  ...     0      0         1   \n",
       "\n",
       "              Wordpress  Xanga  Yelp  Yfrog  Youtube  Yuku  Click  \n",
       "dmp923122274          4      0     0      1        0     1      0  \n",
       "dmp458034174         12      0     2      2       12     0      0  \n",
       "dmp364043571         11      0     0      0        0     0      0  \n",
       "dmp461339655          6      0     0      0       22     0      0  \n",
       "dmp549691332          0      0     0      1        0     0      0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f5d9fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.364452Z",
     "iopub.status.busy": "2023-03-20T12:56:40.364232Z",
     "iopub.status.idle": "2023-03-20T12:56:40.618230Z",
     "shell.execute_reply": "2023-03-20T12:56:40.617238Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.364430Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, dmp923122274 to dmp521609268\n",
      "Data columns (total 82 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Addthis        10000 non-null  int64 \n",
      " 1   Bebo           10000 non-null  int64 \n",
      " 2   Blogcatalog    10000 non-null  int64 \n",
      " 3   Blogger        10000 non-null  int64 \n",
      " 4   Buddymedia     10000 non-null  int64 \n",
      " 5   Cnet           10000 non-null  int64 \n",
      " 6   Conduit        10000 non-null  int64 \n",
      " 7   Customerlobby  10000 non-null  int64 \n",
      " 8   Delicious      10000 non-null  int64 \n",
      " 9   Digg           10000 non-null  int64 \n",
      " 10  Diigo          10000 non-null  object\n",
      " 11  Docs           10000 non-null  int64 \n",
      " 12  Docstoc        10000 non-null  int64 \n",
      " 13  Download       10000 non-null  int64 \n",
      " 14  Dropbox        10000 non-null  int64 \n",
      " 15  Drupal         10000 non-null  int64 \n",
      " 16  Epinions       10000 non-null  int64 \n",
      " 17  Evernote       10000 non-null  int64 \n",
      " 18  Facebook       10000 non-null  int64 \n",
      " 19  Faves          10000 non-null  int64 \n",
      " 20  Feedburner     10000 non-null  int64 \n",
      " 21  Flickr         10000 non-null  int64 \n",
      " 22  Foursquare     10000 non-null  int64 \n",
      " 23  Friendfeed     10000 non-null  int64 \n",
      " 24  Hootsuite      10000 non-null  int64 \n",
      " 25  Joomla         10000 non-null  int64 \n",
      " 26  Jumptags       10000 non-null  int64 \n",
      " 27  Kaboodle       10000 non-null  int64 \n",
      " 28  Kickapps       10000 non-null  int64 \n",
      " 29  Linkedin       10000 non-null  int64 \n",
      " 30  Lithium        10000 non-null  int64 \n",
      " 31  Livejournal    10000 non-null  int64 \n",
      " 32  Mashable       10000 non-null  int64 \n",
      " 33  Meetup         10000 non-null  int64 \n",
      " 34  Metacafe       10000 non-null  int64 \n",
      " 35  Mixx           10000 non-null  int64 \n",
      " 36  Mouthshut      10000 non-null  int64 \n",
      " 37  Multiply       10000 non-null  int64 \n",
      " 38  Mybloglog      10000 non-null  int64 \n",
      " 39  Myspace        10000 non-null  int64 \n",
      " 40  Netvibes       10000 non-null  int64 \n",
      " 41  Newsvine       10000 non-null  int64 \n",
      " 42  Ning           10000 non-null  int64 \n",
      " 43  Orkut          10000 non-null  int64 \n",
      " 44  Photobucket    10000 non-null  int64 \n",
      " 45  Ping           10000 non-null  int64 \n",
      " 46  Pinterest      10000 non-null  int64 \n",
      " 47  Plaxo          10000 non-null  int64 \n",
      " 48  Plurk          10000 non-null  int64 \n",
      " 49  Posterous      10000 non-null  int64 \n",
      " 50  Propeller      10000 non-null  int64 \n",
      " 51  Radian6        10000 non-null  int64 \n",
      " 52  Reddit         10000 non-null  int64 \n",
      " 53  Screencast     10000 non-null  int64 \n",
      " 54  Scribd         10000 non-null  int64 \n",
      " 55  Sharethis      10000 non-null  int64 \n",
      " 56  Slashdot       10000 non-null  int64 \n",
      " 57  Sliderocket    10000 non-null  int64 \n",
      " 58  Slideshare     10000 non-null  int64 \n",
      " 59  Squidoo        10000 non-null  int64 \n",
      " 60  Startaid       10000 non-null  int64 \n",
      " 61  Stumbleupon    10000 non-null  int64 \n",
      " 62  Sysomos        10000 non-null  int64 \n",
      " 63  Technorati     10000 non-null  int64 \n",
      " 64  Thisnext       10000 non-null  int64 \n",
      " 65  Tumblr         10000 non-null  int64 \n",
      " 66  Tweetdeck      10000 non-null  int64 \n",
      " 67  Twine          10000 non-null  int64 \n",
      " 68  Twitter        10000 non-null  int64 \n",
      " 69  Typepad        10000 non-null  int64 \n",
      " 70  Ubertwitter    10000 non-null  int64 \n",
      " 71  Viadeo         10000 non-null  int64 \n",
      " 72  Vimeo          10000 non-null  int64 \n",
      " 73  Vocus          10000 non-null  int64 \n",
      " 74  Wetpaint       10000 non-null  int64 \n",
      " 75  Wordpress      10000 non-null  int64 \n",
      " 76  Xanga          10000 non-null  int64 \n",
      " 77  Yelp           10000 non-null  int64 \n",
      " 78  Yfrog          10000 non-null  int64 \n",
      " 79  Youtube        10000 non-null  int64 \n",
      " 80  Yuku           10000 non-null  int64 \n",
      " 81  Click          10000 non-null  int64 \n",
      "dtypes: int64(81), object(1)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# inspect other aspects as well\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb3724",
   "metadata": {},
   "source": [
    "There are columns which are not numeric!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13c14cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.619177Z",
     "iopub.status.busy": "2023-03-20T12:56:40.618985Z",
     "iopub.status.idle": "2023-03-20T12:56:40.691642Z",
     "shell.execute_reply": "2023-03-20T12:56:40.690808Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.619159Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diigo'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify these columns automatically\n",
    "df.select_dtypes([\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38e215c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.696035Z",
     "iopub.status.busy": "2023-03-20T12:56:40.695558Z",
     "iopub.status.idle": "2023-03-20T12:56:40.786743Z",
     "shell.execute_reply": "2023-03-20T12:56:40.785556Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.696004Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         8842\n",
       "Error: value not found     642\n",
       "1                          332\n",
       "2                          183\n",
       "3                            1\n",
       "Name: Diigo, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check values of this column\n",
    "df[\"Diigo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468673d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.789635Z",
     "iopub.status.busy": "2023-03-20T12:56:40.788982Z",
     "iopub.status.idle": "2023-03-20T12:56:40.823848Z",
     "shell.execute_reply": "2023-03-20T12:56:40.822472Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.789605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace \"Error: value not found\" with NaN\n",
    "df.loc[df[\"Diigo\"]==\"Error: value not found\",\"Diigo\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157d518f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.826898Z",
     "iopub.status.busy": "2023-03-20T12:56:40.825916Z",
     "iopub.status.idle": "2023-03-20T12:56:40.890999Z",
     "shell.execute_reply": "2023-03-20T12:56:40.889733Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.826834Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8842\n",
       "1     332\n",
       "2     183\n",
       "3       1\n",
       "Name: Diigo, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check values again\n",
    "df[\"Diigo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab07366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.893517Z",
     "iopub.status.busy": "2023-03-20T12:56:40.892969Z",
     "iopub.status.idle": "2023-03-20T12:56:40.982839Z",
     "shell.execute_reply": "2023-03-20T12:56:40.981634Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.893484Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to a numeric column as well\n",
    "df[\"Diigo\"] = df[\"Diigo\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9b1bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:40.985761Z",
     "iopub.status.busy": "2023-03-20T12:56:40.985076Z",
     "iopub.status.idle": "2023-03-20T12:56:41.301034Z",
     "shell.execute_reply": "2023-03-20T12:56:41.300378Z",
     "shell.execute_reply.started": "2023-03-20T12:56:40.985710Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Addthis</th>\n",
       "      <th>Bebo</th>\n",
       "      <th>Blogcatalog</th>\n",
       "      <th>Blogger</th>\n",
       "      <th>Buddymedia</th>\n",
       "      <th>Cnet</th>\n",
       "      <th>Conduit</th>\n",
       "      <th>Customerlobby</th>\n",
       "      <th>Delicious</th>\n",
       "      <th>Digg</th>\n",
       "      <th>...</th>\n",
       "      <th>Vimeo</th>\n",
       "      <th>Vocus</th>\n",
       "      <th>Wetpaint</th>\n",
       "      <th>Wordpress</th>\n",
       "      <th>Xanga</th>\n",
       "      <th>Yelp</th>\n",
       "      <th>Yfrog</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>Yuku</th>\n",
       "      <th>Click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.42250</td>\n",
       "      <td>0.78130</td>\n",
       "      <td>0.568100</td>\n",
       "      <td>2.823700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.950400</td>\n",
       "      <td>2.142100</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>1.012700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41190</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>2.176900</td>\n",
       "      <td>0.459500</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>6.040600</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.01405</td>\n",
       "      <td>1.48899</td>\n",
       "      <td>1.197709</td>\n",
       "      <td>5.571438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.937619</td>\n",
       "      <td>3.293993</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.811319</td>\n",
       "      <td>2.266021</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00436</td>\n",
       "      <td>0.196438</td>\n",
       "      <td>0.612402</td>\n",
       "      <td>3.691879</td>\n",
       "      <td>0.982169</td>\n",
       "      <td>1.194696</td>\n",
       "      <td>0.755413</td>\n",
       "      <td>7.892679</td>\n",
       "      <td>0.588856</td>\n",
       "      <td>0.328912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Addthis         Bebo   Blogcatalog       Blogger  Buddymedia  \\\n",
       "count  10000.00000  10000.00000  10000.000000  10000.000000     10000.0   \n",
       "mean       0.42250      0.78130      0.568100      2.823700         0.0   \n",
       "std        1.01405      1.48899      1.197709      5.571438         0.0   \n",
       "min        0.00000      0.00000      0.000000      0.000000         0.0   \n",
       "25%        0.00000      0.00000      0.000000      0.000000         0.0   \n",
       "50%        0.00000      0.00000      0.000000      0.000000         0.0   \n",
       "75%        0.00000      1.00000      0.000000      0.000000         0.0   \n",
       "max        6.00000      8.00000      7.000000     28.000000         0.0   \n",
       "\n",
       "               Cnet       Conduit  Customerlobby     Delicious          Digg  \\\n",
       "count  10000.000000  10000.000000   10000.000000  10000.000000  10000.000000   \n",
       "mean       1.950400      2.142100       0.000200      0.393100      1.012700   \n",
       "std        2.937619      3.293993       0.014141      0.811319      2.266021   \n",
       "min        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000       0.000000      0.000000      0.000000   \n",
       "75%        4.000000      4.000000       0.000000      0.000000      0.000000   \n",
       "max       15.000000     16.000000       1.000000      4.000000     13.000000   \n",
       "\n",
       "       ...        Vimeo         Vocus      Wetpaint     Wordpress  \\\n",
       "count  ...  10000.00000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...      0.41190      0.040200      0.293600      2.176900   \n",
       "std    ...      1.00436      0.196438      0.612402      3.691879   \n",
       "min    ...      0.00000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.00000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.00000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.00000      0.000000      0.000000      4.000000   \n",
       "max    ...      7.00000      1.000000      3.000000     19.000000   \n",
       "\n",
       "              Xanga          Yelp         Yfrog       Youtube          Yuku  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.459500      0.602200      0.380800      6.040600      0.206600   \n",
       "std        0.982169      1.194696      0.755413      7.892679      0.588856   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000     12.000000      0.000000   \n",
       "max        5.000000      7.000000      4.000000     36.000000      4.000000   \n",
       "\n",
       "              Click  \n",
       "count  10000.000000  \n",
       "mean       0.123400  \n",
       "std        0.328912  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 82 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of each variable\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a2ff43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:41.302092Z",
     "iopub.status.busy": "2023-03-20T12:56:41.301859Z",
     "iopub.status.idle": "2023-03-20T12:56:41.315569Z",
     "shell.execute_reply": "2023-03-20T12:56:41.314860Z",
     "shell.execute_reply.started": "2023-03-20T12:56:41.302071Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are columns with less 0 impressions\n",
    "\n",
    "left_outliers = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].min()<0:\n",
    "        left_outliers.append(col)\n",
    "\n",
    "left_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f793ab",
   "metadata": {},
   "source": [
    "There are no left outliers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1ecc7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:41.316620Z",
     "iopub.status.busy": "2023-03-20T12:56:41.316389Z",
     "iopub.status.idle": "2023-03-20T12:56:41.471032Z",
     "shell.execute_reply": "2023-03-20T12:56:41.470222Z",
     "shell.execute_reply.started": "2023-03-20T12:56:41.316599Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Newsvine']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are columns with more than 1000 impressions\n",
    "\n",
    "right_outliers = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].max()>=1000:\n",
    "        right_outliers.append(col)\n",
    "\n",
    "right_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "201965c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:41.473063Z",
     "iopub.status.busy": "2023-03-20T12:56:41.472209Z",
     "iopub.status.idle": "2023-03-20T12:56:41.531415Z",
     "shell.execute_reply": "2023-03-20T12:56:41.530268Z",
     "shell.execute_reply.started": "2023-03-20T12:56:41.473034Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96372367637"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect this column\n",
    "df[\"Newsvine\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91fa8ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:41.534446Z",
     "iopub.status.busy": "2023-03-20T12:56:41.533275Z",
     "iopub.status.idle": "2023-03-20T12:56:41.636911Z",
     "shell.execute_reply": "2023-03-20T12:56:41.635747Z",
     "shell.execute_reply.started": "2023-03-20T12:56:41.534394Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              8443\n",
       "1              1335\n",
       "2               218\n",
       "3                 3\n",
       "96372367637       1\n",
       "Name: Newsvine, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Newsvine\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7edf1f",
   "metadata": {},
   "source": [
    "There is only one off value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6131797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:41.639263Z",
     "iopub.status.busy": "2023-03-20T12:56:41.638724Z",
     "iopub.status.idle": "2023-03-20T12:56:41.729220Z",
     "shell.execute_reply": "2023-03-20T12:56:41.728053Z",
     "shell.execute_reply.started": "2023-03-20T12:56:41.639225Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace max value with NaN\n",
    "df.loc[df[\"Newsvine\"]==df[\"Newsvine\"].max(),\"Newsvine\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bea2320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:41.731969Z",
     "iopub.status.busy": "2023-03-20T12:56:41.731344Z",
     "iopub.status.idle": "2023-03-20T12:56:41.855529Z",
     "shell.execute_reply": "2023-03-20T12:56:41.854385Z",
     "shell.execute_reply.started": "2023-03-20T12:56:41.731925Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    8443\n",
       "1.0    1335\n",
       "2.0     218\n",
       "3.0       3\n",
       "Name: Newsvine, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Newsvine\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "016d58ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:41.858418Z",
     "iopub.status.busy": "2023-03-20T12:56:41.857720Z",
     "iopub.status.idle": "2023-03-20T12:56:42.193865Z",
     "shell.execute_reply": "2023-03-20T12:56:42.193127Z",
     "shell.execute_reply.started": "2023-03-20T12:56:41.858366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Diigo': 642, 'Newsvine': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out columns with NaN and their amount\n",
    "\n",
    "col_with_na = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].isna().sum()>0:\n",
    "        col_with_na[col]=df[col].isna().sum()\n",
    "\n",
    "col_with_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5dc15",
   "metadata": {},
   "source": [
    "Because most values of Diigo are 0 (8842 of 10,000), the decision is to take out this variable because there are a lot of NaN values after preprocessing and SVM cannot deal with NaNs. Also, the one observation of Newsvine should be removed due to the NaN value after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c0bad34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.194823Z",
     "iopub.status.busy": "2023-03-20T12:56:42.194614Z",
     "iopub.status.idle": "2023-03-20T12:56:42.337246Z",
     "shell.execute_reply": "2023-03-20T12:56:42.336451Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.194804Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"Diigo\", axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3283ddd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.338519Z",
     "iopub.status.busy": "2023-03-20T12:56:42.338185Z",
     "iopub.status.idle": "2023-03-20T12:56:42.391577Z",
     "shell.execute_reply": "2023-03-20T12:56:42.390439Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.338495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.341234123412342"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ratio of users who clicked vs. didn't click on the advertisement\n",
    "df[\"Click\"].sum()/df[\"Click\"].count() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc38283",
   "metadata": {},
   "source": [
    "Only 12.34% of the data represents users who clicked on the advertisement. There are too less observations where a user clicked on the advertisement! Therefore, both models need a balancing of the target variable while training (class_weight=\"balanced\")!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1bc52d",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49726ec",
   "metadata": {},
   "source": [
    "##### Splitting into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca96622c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.394367Z",
     "iopub.status.busy": "2023-03-20T12:56:42.393755Z",
     "iopub.status.idle": "2023-03-20T12:56:42.505575Z",
     "shell.execute_reply": "2023-03-20T12:56:42.504357Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.394332Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# divide the data into features and target variable\n",
    "\n",
    "X = df.drop(\"Click\", axis=1)\n",
    "y = df[\"Click\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d69f3059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.517431Z",
     "iopub.status.busy": "2023-03-20T12:56:42.516938Z",
     "iopub.status.idle": "2023-03-20T12:56:42.598524Z",
     "shell.execute_reply": "2023-03-20T12:56:42.597789Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.517396Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ccbe15",
   "metadata": {},
   "source": [
    "##### Implement SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccf7eaf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.600067Z",
     "iopub.status.busy": "2023-03-20T12:56:42.599641Z",
     "iopub.status.idle": "2023-03-20T12:56:42.666857Z",
     "shell.execute_reply": "2023-03-20T12:56:42.666023Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.600044Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale the data for SVM\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75c50c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.667971Z",
     "iopub.status.busy": "2023-03-20T12:56:42.667752Z",
     "iopub.status.idle": "2023-03-20T12:56:42.706207Z",
     "shell.execute_reply": "2023-03-20T12:56:42.705111Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.667952Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use hyperparameter tuning to identify optimal model of these possibilites\n",
    "\n",
    "param_grid = {\"C\": [0.1, 1, 10, 100, 1000],  \n",
    "              \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              \"kernel\": [\"rbf\"]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "195ec9d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.709185Z",
     "iopub.status.busy": "2023-03-20T12:56:42.708434Z",
     "iopub.status.idle": "2023-03-20T12:56:42.796144Z",
     "shell.execute_reply": "2023-03-20T12:56:42.794944Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.709128Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initiate SVM\n",
    "# random_state for reproducibility\n",
    "# class_weight=\"balanced\" because the dataset is inbalanced\n",
    "svm = SVC(random_state=42, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bc510b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.799082Z",
     "iopub.status.busy": "2023-03-20T12:56:42.798380Z",
     "iopub.status.idle": "2023-03-20T12:56:42.917905Z",
     "shell.execute_reply": "2023-03-20T12:56:42.916704Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.799028Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all different possibilities are trained using 5-fold cross validation over training set (no need for validation set therefore)\n",
    "# literature suggests 5- or 10-fold cross validation as best\n",
    "# after identifying the optimal SVM hyperparameters:\n",
    "# a model is trained over best set of hyperparameters over whole training set and used for our predictions later \n",
    "grid_svm = GridSearchCV(estimator=svm, \n",
    "                        param_grid=param_grid, \n",
    "                        refit=True, verbose=3, \n",
    "                        cv=5, \n",
    "                        return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f133852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T12:56:42.920981Z",
     "iopub.status.busy": "2023-03-20T12:56:42.920196Z",
     "iopub.status.idle": "2023-03-20T13:04:28.091291Z",
     "shell.execute_reply": "2023-03-20T13:04:28.090035Z",
     "shell.execute_reply.started": "2023-03-20T12:56:42.920926Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.125, test=0.126) total time=   3.1s\n",
      "[CV 2/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.125, test=0.126) total time=   2.8s\n",
      "[CV 3/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.125, test=0.126) total time=   2.8s\n",
      "[CV 4/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.125, test=0.126) total time=   2.9s\n",
      "[CV 5/5] END C=0.1, gamma=1, kernel=rbf;, score=(train=0.874, test=0.875) total time=   2.9s\n",
      "[CV 1/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.125, test=0.126) total time=   3.1s\n",
      "[CV 2/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.125, test=0.126) total time=   3.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.125, test=0.126) total time=   3.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.125, test=0.126) total time=   3.1s\n",
      "[CV 5/5] END C=0.1, gamma=0.1, kernel=rbf;, score=(train=0.874, test=0.875) total time=   3.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.866, test=0.854) total time=   1.8s\n",
      "[CV 2/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.864, test=0.861) total time=   1.8s\n",
      "[CV 3/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.865, test=0.849) total time=   1.8s\n",
      "[CV 4/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.863, test=0.856) total time=   1.9s\n",
      "[CV 5/5] END C=0.1, gamma=0.01, kernel=rbf;, score=(train=0.862, test=0.840) total time=   1.8s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.847, test=0.841) total time=   2.6s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.845, test=0.843) total time=   2.7s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.843, test=0.846) total time=   2.9s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.843, test=0.846) total time=   2.7s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.844, test=0.831) total time=   2.8s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.785, test=0.783) total time=   3.6s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.625, test=0.625) total time=   3.6s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.684, test=0.682) total time=   3.6s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.695, test=0.713) total time=   3.6s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.874, test=0.875) total time=   3.5s\n",
      "[CV 1/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.1s\n",
      "[CV 2/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.1s\n",
      "[CV 3/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.1s\n",
      "[CV 4/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.2s\n",
      "[CV 5/5] END C=1, gamma=1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   3.1s\n",
      "[CV 1/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.2s\n",
      "[CV 2/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.1s\n",
      "[CV 3/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.1s\n",
      "[CV 4/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.2s\n",
      "[CV 5/5] END C=1, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   3.1s\n",
      "[CV 1/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.989, test=0.956) total time=   0.9s\n",
      "[CV 2/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.991, test=0.961) total time=   0.9s\n",
      "[CV 3/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.993, test=0.953) total time=   1.0s\n",
      "[CV 4/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.991, test=0.958) total time=   1.0s\n",
      "[CV 5/5] END C=1, gamma=0.01, kernel=rbf;, score=(train=0.992, test=0.958) total time=   1.0s\n",
      "[CV 1/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.914, test=0.906) total time=   1.1s\n",
      "[CV 2/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.910, test=0.924) total time=   1.1s\n",
      "[CV 3/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.915, test=0.905) total time=   1.1s\n",
      "[CV 4/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.920, test=0.910) total time=   1.1s\n",
      "[CV 5/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.914, test=0.906) total time=   1.1s\n",
      "[CV 1/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.855, test=0.852) total time=   2.4s\n",
      "[CV 2/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.855, test=0.852) total time=   2.4s\n",
      "[CV 3/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.852, test=0.854) total time=   2.4s\n",
      "[CV 4/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.851, test=0.858) total time=   2.4s\n",
      "[CV 5/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.850, test=0.838) total time=   2.4s\n",
      "[CV 1/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.8s\n",
      "[CV 2/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 3/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 4/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 5/5] END C=10, gamma=1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   2.9s\n",
      "[CV 1/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.8s\n",
      "[CV 2/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 3/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 4/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 5/5] END C=10, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   2.8s\n",
      "[CV 1/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.963) total time=   0.7s\n",
      "[CV 2/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   0.7s\n",
      "[CV 3/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.958) total time=   0.7s\n",
      "[CV 4/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   0.7s\n",
      "[CV 5/5] END C=10, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.966) total time=   0.7s\n",
      "[CV 1/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.964, test=0.953) total time=   0.5s\n",
      "[CV 2/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.964, test=0.960) total time=   0.5s\n",
      "[CV 3/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.965, test=0.950) total time=   0.5s\n",
      "[CV 4/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.962, test=0.956) total time=   0.5s\n",
      "[CV 5/5] END C=10, gamma=0.001, kernel=rbf;, score=(train=0.966, test=0.949) total time=   0.5s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.914, test=0.911) total time=   1.1s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.910, test=0.926) total time=   1.0s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.915, test=0.909) total time=   1.1s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.922, test=0.913) total time=   1.1s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=rbf;, score=(train=0.916, test=0.904) total time=   1.1s\n",
      "[CV 1/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 2/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 3/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 4/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 5/5] END C=100, gamma=1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   2.9s\n",
      "[CV 1/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 2/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.0s\n",
      "[CV 3/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 4/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   3.0s\n",
      "[CV 5/5] END C=100, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   2.9s\n",
      "[CV 1/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.963) total time=   0.7s\n",
      "[CV 2/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   0.7s\n",
      "[CV 3/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.958) total time=   0.7s\n",
      "[CV 4/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   0.7s\n",
      "[CV 5/5] END C=100, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.966) total time=   0.7s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.997, test=0.969) total time=   0.4s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.997, test=0.973) total time=   0.4s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.997, test=0.968) total time=   0.4s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.997, test=0.971) total time=   0.4s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=rbf;, score=(train=0.997, test=0.971) total time=   0.4s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.950, test=0.944) total time=   0.5s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.948, test=0.957) total time=   0.5s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.953, test=0.944) total time=   0.5s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.949, test=0.948) total time=   0.5s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=rbf;, score=(train=0.952, test=0.946) total time=   0.5s\n",
      "[CV 1/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.8s\n",
      "[CV 2/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.8s\n",
      "[CV 3/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.8s\n",
      "[CV 4/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.8s\n",
      "[CV 5/5] END C=1000, gamma=1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   2.8s\n",
      "[CV 1/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 2/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 3/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 4/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.874) total time=   2.9s\n",
      "[CV 5/5] END C=1000, gamma=0.1, kernel=rbf;, score=(train=1.000, test=0.875) total time=   2.9s\n",
      "[CV 1/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.963) total time=   0.7s\n",
      "[CV 2/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   0.7s\n",
      "[CV 3/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.958) total time=   0.7s\n",
      "[CV 4/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.959) total time=   0.7s\n",
      "[CV 5/5] END C=1000, gamma=0.01, kernel=rbf;, score=(train=1.000, test=0.966) total time=   0.7s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.969) total time=   0.5s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.975) total time=   0.5s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.964) total time=   0.4s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.966) total time=   0.5s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=rbf;, score=(train=1.000, test=0.971) total time=   0.5s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.972, test=0.961) total time=   0.4s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.971, test=0.967) total time=   0.4s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.975, test=0.957) total time=   0.4s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.974, test=0.967) total time=   0.4s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=rbf;, score=(train=0.974, test=0.961) total time=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(class_weight=&#x27;balanced&#x27;, random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             return_train_score=True, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(class_weight=&#x27;balanced&#x27;, random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             return_train_score=True, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(class_weight='balanced', random_state=42),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model for grid search\n",
    "grid_svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9667d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:04:28.093540Z",
     "iopub.status.busy": "2023-03-20T13:04:28.093318Z",
     "iopub.status.idle": "2023-03-20T13:04:28.100599Z",
     "shell.execute_reply": "2023-03-20T13:04:28.100007Z",
     "shell.execute_reply.started": "2023-03-20T13:04:28.093520Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "SVC(C=100, class_weight='balanced', gamma=0.001, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid_svm.best_params_)\n",
    "  \n",
    "# print how our model looks after hyperparameter tuning\n",
    "print(grid_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f410f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:04:28.101743Z",
     "iopub.status.busy": "2023-03-20T13:04:28.101577Z",
     "iopub.status.idle": "2023-03-20T13:04:28.716543Z",
     "shell.execute_reply": "2023-03-20T13:04:28.715331Z",
     "shell.execute_reply.started": "2023-03-20T13:04:28.101728Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the confusion matrix \n",
      " [[6965   30]\n",
      " [   0 1004]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6995\n",
      "           1       0.97      1.00      0.99      1004\n",
      "\n",
      "    accuracy                           1.00      7999\n",
      "   macro avg       0.99      1.00      0.99      7999\n",
      "weighted avg       1.00      1.00      1.00      7999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check scores on training set \n",
    "\n",
    "# get predictions on training set \n",
    "grid_predictions = grid_svm.predict(X_train_scaled)\n",
    "\n",
    "#print confusion matrix\n",
    "print(\"This is the confusion matrix \\n\",\n",
    "      confusion_matrix(y_train, grid_predictions), \"\\n\")\n",
    "\n",
    "# print classification report \n",
    "# includes precision recall f1-score and support \n",
    "print(classification_report(y_train, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "782be47b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:04:28.717435Z",
     "iopub.status.busy": "2023-03-20T13:04:28.717266Z",
     "iopub.status.idle": "2023-03-20T13:04:28.841633Z",
     "shell.execute_reply": "2023-03-20T13:04:28.840961Z",
     "shell.execute_reply.started": "2023-03-20T13:04:28.717419Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the confusion matrix \n",
      " [[1730   40]\n",
      " [  19  211]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1770\n",
      "           1       0.84      0.92      0.88       230\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.91      0.95      0.93      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check scores on test set \n",
    "\n",
    "# get predictions on test set \n",
    "grid_predictions = grid_svm.predict(X_test_scaled)\n",
    "\n",
    "#print confusion matrix\n",
    "print(\"This is the confusion matrix \\n\",\n",
    "      confusion_matrix(y_test, grid_predictions), \"\\n\")\n",
    "\n",
    "# print classification report \n",
    "# includes precision, recall, f1-score and support \n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e5168-b0d6-40c4-bf5b-c504c6a27ed8",
   "metadata": {},
   "source": [
    "The f1-score on the unseen test set of the SVM is 97%. However, the performance predicting class 1 is lower due to the imbalance of the target variable in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb677b",
   "metadata": {},
   "source": [
    "##### Implement Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48db4ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:04:28.842784Z",
     "iopub.status.busy": "2023-03-20T13:04:28.842589Z",
     "iopub.status.idle": "2023-03-20T13:04:28.970446Z",
     "shell.execute_reply": "2023-03-20T13:04:28.969189Z",
     "shell.execute_reply.started": "2023-03-20T13:04:28.842769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initiate random forest classifier\n",
    "# random_state for reproducibility\n",
    "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ed3a54f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:04:28.974366Z",
     "iopub.status.busy": "2023-03-20T13:04:28.973044Z",
     "iopub.status.idle": "2023-03-20T13:04:29.072392Z",
     "shell.execute_reply": "2023-03-20T13:04:29.071184Z",
     "shell.execute_reply.started": "2023-03-20T13:04:28.974275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use hyperparameter tuning to identify optimal model of these possibilites\n",
    "\n",
    "param_grid = {\"n_estimators\": [300, 500, 1000],\n",
    "              \"max_depth\": [1, 3, 5, 10],\n",
    "              \"min_samples_split\": [2, 4, 6, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "277cccd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:04:29.075199Z",
     "iopub.status.busy": "2023-03-20T13:04:29.074653Z",
     "iopub.status.idle": "2023-03-20T13:04:29.233863Z",
     "shell.execute_reply": "2023-03-20T13:04:29.232670Z",
     "shell.execute_reply.started": "2023-03-20T13:04:29.075147Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all different possibilities are trained using 5-fold cross validation over training set (no need for validation set therefore)\n",
    "# literature suggests 5- or 10-fold cross validation as best\n",
    "# after identifying the optimal random forest hyperparameters:\n",
    "# a model is trained over best set of hyperparameters over whole training set and used for our predictions later\n",
    "grid_rf = GridSearchCV(estimator=rf, \n",
    "                       param_grid=param_grid, \n",
    "                       refit=True, verbose=3, \n",
    "                       cv=5,\n",
    "                       return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d66473b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:04:29.236940Z",
     "iopub.status.busy": "2023-03-20T13:04:29.236223Z",
     "iopub.status.idle": "2023-03-20T13:12:32.526845Z",
     "shell.execute_reply": "2023-03-20T13:12:32.526180Z",
     "shell.execute_reply.started": "2023-03-20T13:04:29.236873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.833, test=0.824) total time=   0.6s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.836, test=0.818) total time=   0.5s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.823, test=0.814) total time=   0.5s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.825, test=0.821) total time=   0.5s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=2, n_estimators=300;, score=(train=0.832, test=0.833) total time=   0.5s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.833, test=0.817) total time=   0.9s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.837, test=0.821) total time=   0.9s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.830, test=0.821) total time=   0.9s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.827, test=0.820) total time=   0.9s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=2, n_estimators=500;, score=(train=0.836, test=0.834) total time=   0.9s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.834, test=0.827) total time=   1.8s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.836, test=0.819) total time=   1.8s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.831, test=0.828) total time=   1.8s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.830, test=0.823) total time=   1.8s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=2, n_estimators=1000;, score=(train=0.836, test=0.831) total time=   1.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.833, test=0.824) total time=   0.5s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.836, test=0.818) total time=   0.5s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.823, test=0.814) total time=   0.5s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.825, test=0.821) total time=   0.5s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=4, n_estimators=300;, score=(train=0.832, test=0.833) total time=   0.5s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.833, test=0.817) total time=   0.9s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.837, test=0.821) total time=   0.9s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.830, test=0.821) total time=   0.9s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.827, test=0.820) total time=   0.9s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=4, n_estimators=500;, score=(train=0.836, test=0.834) total time=   0.9s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.834, test=0.827) total time=   1.8s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.836, test=0.819) total time=   1.8s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.831, test=0.828) total time=   1.8s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.830, test=0.823) total time=   1.8s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=4, n_estimators=1000;, score=(train=0.836, test=0.831) total time=   1.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.833, test=0.824) total time=   0.5s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.836, test=0.818) total time=   0.5s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.823, test=0.814) total time=   0.5s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.825, test=0.821) total time=   0.5s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=6, n_estimators=300;, score=(train=0.832, test=0.833) total time=   0.5s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.833, test=0.817) total time=   0.9s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.837, test=0.821) total time=   0.9s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.830, test=0.821) total time=   0.9s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.827, test=0.820) total time=   0.9s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=6, n_estimators=500;, score=(train=0.836, test=0.834) total time=   0.9s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.834, test=0.827) total time=   1.8s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.836, test=0.819) total time=   1.8s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.831, test=0.828) total time=   1.9s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.830, test=0.823) total time=   1.8s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=6, n_estimators=1000;, score=(train=0.836, test=0.831) total time=   1.8s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.833, test=0.824) total time=   0.5s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.836, test=0.818) total time=   0.5s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.823, test=0.814) total time=   0.5s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.825, test=0.821) total time=   0.6s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=8, n_estimators=300;, score=(train=0.832, test=0.833) total time=   0.5s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.833, test=0.817) total time=   0.9s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.837, test=0.821) total time=   0.9s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.830, test=0.821) total time=   0.9s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.827, test=0.820) total time=   0.9s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=8, n_estimators=500;, score=(train=0.836, test=0.834) total time=   0.9s\n",
      "[CV 1/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.834, test=0.827) total time=   1.8s\n",
      "[CV 2/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.836, test=0.819) total time=   1.8s\n",
      "[CV 3/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.831, test=0.828) total time=   1.8s\n",
      "[CV 4/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.830, test=0.823) total time=   1.8s\n",
      "[CV 5/5] END max_depth=1, min_samples_split=8, n_estimators=1000;, score=(train=0.836, test=0.831) total time=   1.7s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.856, test=0.839) total time=   0.7s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.857, test=0.836) total time=   0.7s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.846, test=0.828) total time=   0.7s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.854, test=0.841) total time=   0.7s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=300;, score=(train=0.858, test=0.842) total time=   0.7s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.854, test=0.840) total time=   1.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.857, test=0.840) total time=   1.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.849, test=0.833) total time=   1.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.854, test=0.836) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=500;, score=(train=0.859, test=0.849) total time=   1.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.856, test=0.842) total time=   2.4s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.855, test=0.836) total time=   2.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.851, test=0.832) total time=   2.4s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.853, test=0.838) total time=   2.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=2, n_estimators=1000;, score=(train=0.859, test=0.847) total time=   2.4s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.856, test=0.839) total time=   0.7s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.857, test=0.836) total time=   0.7s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.846, test=0.828) total time=   0.7s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.854, test=0.841) total time=   0.7s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=4, n_estimators=300;, score=(train=0.858, test=0.842) total time=   0.7s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.854, test=0.840) total time=   1.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.856, test=0.839) total time=   1.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.849, test=0.833) total time=   1.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.854, test=0.836) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=4, n_estimators=500;, score=(train=0.859, test=0.849) total time=   1.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.856, test=0.842) total time=   2.4s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.855, test=0.836) total time=   2.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.851, test=0.832) total time=   2.4s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.853, test=0.838) total time=   2.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=4, n_estimators=1000;, score=(train=0.859, test=0.847) total time=   2.4s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.856, test=0.839) total time=   0.7s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.857, test=0.836) total time=   0.7s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.846, test=0.828) total time=   0.7s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.854, test=0.841) total time=   0.7s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=6, n_estimators=300;, score=(train=0.858, test=0.842) total time=   0.7s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.854, test=0.840) total time=   1.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.856, test=0.839) total time=   1.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.849, test=0.833) total time=   1.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.854, test=0.836) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=6, n_estimators=500;, score=(train=0.859, test=0.849) total time=   1.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.856, test=0.842) total time=   2.4s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.855, test=0.836) total time=   2.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.851, test=0.832) total time=   2.4s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.853, test=0.838) total time=   2.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=6, n_estimators=1000;, score=(train=0.859, test=0.847) total time=   2.4s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.856, test=0.839) total time=   0.7s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.857, test=0.836) total time=   0.7s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.846, test=0.828) total time=   0.7s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.854, test=0.841) total time=   0.7s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=8, n_estimators=300;, score=(train=0.858, test=0.842) total time=   0.7s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.854, test=0.840) total time=   1.2s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.856, test=0.839) total time=   1.2s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.849, test=0.833) total time=   1.2s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.854, test=0.836) total time=   1.2s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=8, n_estimators=500;, score=(train=0.859, test=0.849) total time=   1.2s\n",
      "[CV 1/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.856, test=0.842) total time=   2.5s\n",
      "[CV 2/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.855, test=0.836) total time=   2.4s\n",
      "[CV 3/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.851, test=0.832) total time=   2.4s\n",
      "[CV 4/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.853, test=0.838) total time=   2.4s\n",
      "[CV 5/5] END max_depth=3, min_samples_split=8, n_estimators=1000;, score=(train=0.859, test=0.847) total time=   2.4s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.897, test=0.862) total time=   0.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.899, test=0.863) total time=   0.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.893, test=0.861) total time=   0.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.899, test=0.869) total time=   0.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=300;, score=(train=0.902, test=0.873) total time=   0.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.896, test=0.863) total time=   1.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.901, test=0.862) total time=   1.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.899, test=0.868) total time=   1.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.898, test=0.865) total time=   1.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=500;, score=(train=0.906, test=0.876) total time=   1.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.899, test=0.866) total time=   3.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.900, test=0.864) total time=   3.1s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.898, test=0.869) total time=   3.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.901, test=0.865) total time=   3.1s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=2, n_estimators=1000;, score=(train=0.907, test=0.881) total time=   3.0s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.897, test=0.861) total time=   0.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.900, test=0.864) total time=   0.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.893, test=0.863) total time=   0.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.899, test=0.869) total time=   0.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=4, n_estimators=300;, score=(train=0.902, test=0.874) total time=   0.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.896, test=0.864) total time=   1.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.902, test=0.861) total time=   1.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.899, test=0.868) total time=   1.6s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.899, test=0.865) total time=   1.5s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=4, n_estimators=500;, score=(train=0.908, test=0.877) total time=   1.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.899, test=0.864) total time=   2.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.899, test=0.866) total time=   3.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.898, test=0.868) total time=   2.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.901, test=0.866) total time=   3.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=4, n_estimators=1000;, score=(train=0.907, test=0.879) total time=   2.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.897, test=0.859) total time=   0.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.898, test=0.862) total time=   0.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.893, test=0.864) total time=   0.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.898, test=0.870) total time=   0.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=6, n_estimators=300;, score=(train=0.900, test=0.874) total time=   0.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.895, test=0.861) total time=   1.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.901, test=0.863) total time=   1.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.900, test=0.868) total time=   1.5s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.898, test=0.866) total time=   1.5s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=6, n_estimators=500;, score=(train=0.907, test=0.878) total time=   1.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.898, test=0.865) total time=   3.0s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.899, test=0.866) total time=   3.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.897, test=0.867) total time=   3.0s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.902, test=0.864) total time=   3.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=6, n_estimators=1000;, score=(train=0.907, test=0.876) total time=   2.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.897, test=0.861) total time=   0.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.898, test=0.861) total time=   0.9s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.894, test=0.862) total time=   0.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.898, test=0.869) total time=   0.9s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=8, n_estimators=300;, score=(train=0.900, test=0.876) total time=   0.9s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.895, test=0.861) total time=   1.5s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.900, test=0.861) total time=   1.5s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.900, test=0.869) total time=   1.5s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.898, test=0.869) total time=   1.6s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=8, n_estimators=500;, score=(train=0.907, test=0.878) total time=   1.5s\n",
      "[CV 1/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.898, test=0.864) total time=   2.9s\n",
      "[CV 2/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.899, test=0.866) total time=   3.0s\n",
      "[CV 3/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.897, test=0.868) total time=   2.9s\n",
      "[CV 4/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.902, test=0.866) total time=   3.0s\n",
      "[CV 5/5] END max_depth=5, min_samples_split=8, n_estimators=1000;, score=(train=0.907, test=0.878) total time=   2.9s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.998, test=0.884) total time=   1.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.998, test=0.885) total time=   1.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.998, test=0.879) total time=   1.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.998, test=0.879) total time=   1.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=300;, score=(train=0.999, test=0.883) total time=   1.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.998, test=0.883) total time=   2.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.999, test=0.885) total time=   2.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.999, test=0.879) total time=   2.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.999, test=0.881) total time=   2.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=500;, score=(train=0.999, test=0.882) total time=   2.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.998, test=0.885) total time=   4.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.999, test=0.884) total time=   4.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.999, test=0.878) total time=   4.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.999, test=0.881) total time=   4.8s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=2, n_estimators=1000;, score=(train=0.999, test=0.882) total time=   4.8s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.998, test=0.886) total time=   1.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.999, test=0.884) total time=   1.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.998, test=0.883) total time=   1.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.998, test=0.881) total time=   1.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=4, n_estimators=300;, score=(train=0.998, test=0.885) total time=   1.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.998, test=0.885) total time=   2.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.999, test=0.884) total time=   2.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.998, test=0.881) total time=   2.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.999, test=0.884) total time=   2.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=4, n_estimators=500;, score=(train=0.998, test=0.887) total time=   2.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.998, test=0.885) total time=   4.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.999, test=0.884) total time=   4.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.999, test=0.882) total time=   4.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.998, test=0.884) total time=   4.8s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=4, n_estimators=1000;, score=(train=0.999, test=0.886) total time=   4.8s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.998, test=0.886) total time=   1.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.999, test=0.887) total time=   1.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.997, test=0.884) total time=   1.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.999, test=0.885) total time=   1.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=6, n_estimators=300;, score=(train=0.998, test=0.887) total time=   1.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.998, test=0.886) total time=   2.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.999, test=0.887) total time=   2.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.998, test=0.883) total time=   2.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.998, test=0.884) total time=   2.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=6, n_estimators=500;, score=(train=0.998, test=0.887) total time=   2.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.998, test=0.887) total time=   4.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.999, test=0.887) total time=   4.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.998, test=0.883) total time=   4.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.998, test=0.887) total time=   4.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=6, n_estimators=1000;, score=(train=0.998, test=0.888) total time=   4.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.998, test=0.896) total time=   1.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.998, test=0.887) total time=   1.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.997, test=0.885) total time=   1.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.999, test=0.891) total time=   1.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=8, n_estimators=300;, score=(train=0.998, test=0.890) total time=   1.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.998, test=0.893) total time=   2.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.998, test=0.889) total time=   2.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.998, test=0.886) total time=   2.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.999, test=0.892) total time=   2.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=8, n_estimators=500;, score=(train=0.999, test=0.889) total time=   2.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.998, test=0.892) total time=   4.7s\n",
      "[CV 2/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.998, test=0.891) total time=   4.7s\n",
      "[CV 3/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.998, test=0.886) total time=   4.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.998, test=0.887) total time=   4.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_split=8, n_estimators=1000;, score=(train=0.999, test=0.890) total time=   4.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                              random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4, 6, 8],\n",
       "                         &#x27;n_estimators&#x27;: [300, 500, 1000]},\n",
       "             return_train_score=True, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                              random_state=42),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 3, 5, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4, 6, 8],\n",
       "                         &#x27;n_estimators&#x27;: [300, 500, 1000]},\n",
       "             return_train_score=True, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              random_state=42),\n",
       "             param_grid={'max_depth': [1, 3, 5, 10],\n",
       "                         'min_samples_split': [2, 4, 6, 8],\n",
       "                         'n_estimators': [300, 500, 1000]},\n",
       "             return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model for grid search\n",
    "# not using scaled data because random forest has not this assumption\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48e1bcc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:12:32.527951Z",
     "iopub.status.busy": "2023-03-20T13:12:32.527752Z",
     "iopub.status.idle": "2023-03-20T13:12:32.533336Z",
     "shell.execute_reply": "2023-03-20T13:12:32.532743Z",
     "shell.execute_reply.started": "2023-03-20T13:12:32.527934Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_split': 8, 'n_estimators': 300}\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
      "                       min_samples_split=8, n_estimators=300, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid_rf.best_params_)\n",
    "  \n",
    "# print how our model looks after hyperparameter tuning\n",
    "print(grid_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ca74ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:12:32.534467Z",
     "iopub.status.busy": "2023-03-20T13:12:32.534298Z",
     "iopub.status.idle": "2023-03-20T13:12:33.054863Z",
     "shell.execute_reply": "2023-03-20T13:12:33.054183Z",
     "shell.execute_reply.started": "2023-03-20T13:12:32.534451Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the confusion matrix \n",
      " [[6987    8]\n",
      " [  20  984]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6995\n",
      "           1       0.99      0.98      0.99      1004\n",
      "\n",
      "    accuracy                           1.00      7999\n",
      "   macro avg       0.99      0.99      0.99      7999\n",
      "weighted avg       1.00      1.00      1.00      7999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check scores on training set \n",
    "\n",
    "# get predictions on training set \n",
    "grid_predictions = grid_rf.predict(X_train)\n",
    "\n",
    "#print confusion matrix\n",
    "print(\"This is the confusion matrix \\n\",\n",
    "      confusion_matrix(y_train, grid_predictions), \"\\n\")\n",
    "\n",
    "# print classification report \n",
    "# includes precision recall f1-score and support \n",
    "print(classification_report(y_train, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "003c1b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:12:33.055719Z",
     "iopub.status.busy": "2023-03-20T13:12:33.055554Z",
     "iopub.status.idle": "2023-03-20T13:12:33.142469Z",
     "shell.execute_reply": "2023-03-20T13:12:33.141544Z",
     "shell.execute_reply.started": "2023-03-20T13:12:33.055704Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the confusion matrix \n",
      " [[1752   18]\n",
      " [ 172   58]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      1770\n",
      "           1       0.76      0.25      0.38       230\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.84      0.62      0.66      2000\n",
      "weighted avg       0.89      0.91      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check scores on test set \n",
    "\n",
    "# get predictions on test set \n",
    "grid_predictions = grid_rf.predict(X_test)\n",
    "\n",
    "#print confusion matrix\n",
    "print(\"This is the confusion matrix \\n\",\n",
    "      confusion_matrix(y_test, grid_predictions), \"\\n\")\n",
    "\n",
    "# print classification report \n",
    "# includes precision, recall, f1-score, and support \n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d21b24-2a9e-481d-9ba6-850da5b47adf",
   "metadata": {},
   "source": [
    "The f1-score on the unseen test set of the random forest is 88%. However, the random forest classifier is not very good at predicting class 1 due to the unbalance of the target variable in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40475e96-bb1a-48e4-b987-fe9e8f2e986c",
   "metadata": {},
   "source": [
    "##### Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee0c23-fdda-4e86-b62c-7ed1d3233327",
   "metadata": {},
   "source": [
    "Previously, a SVM classifier and a random forest classifier was trained. After splitting the dataset into training and test set, the training set was used to search for suitable hyperparameters for each model using 3-fold cross validation. Therefore, no hold-out dataset had to be created. After training, the models were used to compare performance by predicting on the test set.\n",
    "\n",
    "Comparing both algorithm, the SVM algorithm is better for this kind of supervised machine learning problem due to the unbalance of the dataset. The SVM is searching for a hyperplane to separate both classes, therefore, having ann unbalanced dataset can be kind of offset. The random forest suffers from this problem! \n",
    "\n",
    "SVM F1-score: 97% on test set!\n",
    "\n",
    "Random forest F1-score: 88% on test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27267bb1",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a55e3d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:12:33.143506Z",
     "iopub.status.busy": "2023-03-20T13:12:33.143335Z",
     "iopub.status.idle": "2023-03-20T13:12:33.165867Z",
     "shell.execute_reply": "2023-03-20T13:12:33.164707Z",
     "shell.execute_reply.started": "2023-03-20T13:12:33.143491Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def most_important_features(original_dataframe, rf_model):\n",
    "    '''\n",
    "    Input:\n",
    "    original_dataframe: original dataframe used to train rf (used to extract feature names)\n",
    "    rf_model: saved random forest model\n",
    "    \n",
    "    Output:\n",
    "    Function prints out 5 most important features and plots them as barchart\n",
    "    '''\n",
    "    temp1 = []\n",
    "    temp2 = []\n",
    "\n",
    "    for name, score in zip(original_dataframe.columns, rf_model.best_estimator_.feature_importances_):\n",
    "        temp1.append(name)\n",
    "        temp2.append(score)\n",
    "\n",
    "    dictionary = {\"feature\" : temp1, \"relative_importance\" : temp2}\n",
    "\n",
    "    feature_importance = pd.DataFrame(dictionary).set_index(\"feature\")\n",
    "\n",
    "    feature_importance.sort_values(by=\"relative_importance\", ascending=False, inplace=True)\n",
    "\n",
    "    print(\"These are the 5 most important features according to the random forest model: \\n\")\n",
    "    print(feature_importance[:5])\n",
    "\n",
    "    # plot the features and their relative_importance\n",
    "    plt.bar(list(feature_importance.index[:5]), feature_importance[\"relative_importance\"][:5])\n",
    "    plt.title(\"5 most important features according to random forest model\")\n",
    "    plt.xlabel(\"Marketing Channel\")\n",
    "    plt.ylabel(\"Relative Importance (in %)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9244275d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-20T13:12:33.166982Z",
     "iopub.status.busy": "2023-03-20T13:12:33.166751Z",
     "iopub.status.idle": "2023-03-20T13:12:33.538480Z",
     "shell.execute_reply": "2023-03-20T13:12:33.537720Z",
     "shell.execute_reply.started": "2023-03-20T13:12:33.166960Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the 5 most important features according to the random forest model: \n",
      "\n",
      "             relative_importance\n",
      "feature                         \n",
      "Wordpress               0.060989\n",
      "Livejournal             0.058918\n",
      "Thisnext                0.055135\n",
      "Blogger                 0.050350\n",
      "Yelp                    0.046696\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the function\n",
    "most_important_features(df, grid_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccf6ce",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e76e5",
   "metadata": {},
   "source": [
    "If the company wants to use most effective channels, they should follow the most important features from the random forest model as these were the most crucial ones regarding efficiency:\n",
    "\n",
    "In this case, the best channel is \"Wordpress\" (6.10% relative importance) followed by \"Livejournal\" (5.89% relative importance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320ea63",
   "metadata": {},
   "source": [
    "### 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be9aab",
   "metadata": {},
   "source": [
    "If the cost of impressions are the same for all channels, the most efficient channels (fewer impressions per click) are best to choose.\n",
    "\n",
    "Therefore, the answer is the same as in task 3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
